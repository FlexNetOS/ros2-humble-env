[workspace]
name = "robostack"
description = "Development environment for RoboStack ROS packages"
channels = ["robostack-humble", "conda-forge"]
platforms = ["linux-64", "osx-64", "osx-arm64", "linux-aarch64"]

[dependencies]
python = ">=3.11.14,<3.12"

# Build tools
compilers = ">=1.11.0,<2"
cmake = ">=4.2.0,<5"
pkg-config = ">=0.29.2,<0.30"
make = ">=4.4.1,<5"
ninja = ">=1.13.2,<2"

# Compilation cache & fast linking
ccache = ">=4.10,<5"
sccache = ">=0.8,<1"

# Note: Rust toolchain for Agent Gateway comes from Nix, not pixi
# (cargo/rust not available on all platforms in conda-forge)

# Archive/Network tools (for tree-sitter)
tar = ">=1.34"
curl = ">=8.0"

# Node.js ecosystem (for LazyVim plugins like peek.nvim, live-preview.nvim)
nodejs = ">=22.0,<23"    # LTS "Jod" - active until Apr 2027
pnpm = ">=9.0"

# ROS specific tools
rosdep = ">=0.26.0,<0.27"
colcon-common-extensions = ">=0.3.0,<0.4"
ros-humble-desktop = ">=0.10.0,<0.11"
catkin_tools = ">=0.8.2,<0.10"

# PyTorch ML stack (CPU by default, CUDA via feature)
# Using conda-forge for native performance and ROS2 compatibility
# See docs/CONFLICTS.md for Python 3.14 and CUDA analysis
pytorch = ">=2.5,<3"
torchvision = ">=0.20,<1"
torchaudio = ">=2.5,<3"

[feature.cuda]
# CUDA-enabled PyTorch (requires NVIDIA GPU)
# Activate with: pixi run -e cuda <command>
platforms = ["linux-64"]
channels = ["pytorch", "nvidia", "conda-forge"]

[feature.cuda.dependencies]
# PyTorch with CUDA from pytorch channel
pytorch = { version = ">=2.5,<3", channel = "pytorch" }
torchvision = { version = ">=0.20,<1", channel = "pytorch" }
torchaudio = { version = ">=2.5,<3", channel = "pytorch" }
pytorch-cuda = { version = ">=12.4", channel = "pytorch" }

[environments]
default = { features = [], solve-group = "default" }
cuda = { features = ["cuda"], solve-group = "cuda" }
