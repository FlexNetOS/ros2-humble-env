[workspace]
name = "robostack"
description = "Development environment for RoboStack ROS packages"
channels = ["robostack-humble", "conda-forge"]
platforms = ["linux-64", "osx-64", "osx-arm64", "linux-aarch64"]

[dependencies]
python = ">=3.11,<3.12"

# Build tools
compilers = ">=1.11.0,<2"
cmake = ">=4.2.0,<5"
pkg-config = ">=0.29.2,<0.30"
make = ">=4.4.1,<5"
ninja = ">=1.13.2,<2"

# Compilation cache & fast linking
ccache = ">=4.10,<5"
sccache = ">=0.8,<1"

# Note: Rust toolchain for Agent Gateway comes from Nix, not pixi
# (cargo/rust not available on all platforms in conda-forge)

# Archive/Network tools (for tree-sitter)
tar = ">=1.34"
curl = ">=8.0"

# Node.js ecosystem (for LazyVim plugins like peek.nvim, live-preview.nvim)
nodejs = ">=22.0,<23"    # LTS "Jod" - active until Apr 2027
pnpm = ">=9.0"

# ROS specific tools
rosdep = ">=0.26.0,<0.27"
colcon-common-extensions = ">=0.3.0,<0.4"
ros-humble-desktop = ">=0.10.0,<0.11"
catkin_tools = ">=0.8.2,<0.10"

# Testing & Code Quality
pytest = ">=7.0,<9"
pytest-cov = ">=4.0,<6"
mypy = ">=1.0,<2"
black = ">=24.0,<25"
isort = ">=5.0,<6"

# Scientific/ML dependencies (explicit)
numpy = ">=1.24,<3"

# PyTorch ML stack (CPU by default, CUDA via feature)
# Using conda-forge for native performance and ROS2 compatibility
# See docs/CONFLICTS.md for Python 3.14 and CUDA analysis
# Note: Version coupling - PyTorch 2.5.x requires torchvision 0.20.x, torchaudio 2.5.x
pytorch = ">=2.5,<2.6"
torchvision = ">=0.20,<0.21"
torchaudio = ">=2.5,<2.6"

[feature.cuda]
# CUDA-enabled PyTorch (requires NVIDIA GPU)
# Activate with: pixi run -e cuda <command>
platforms = ["linux-64"]
channels = ["pytorch", "nvidia", "conda-forge"]

[feature.cuda.dependencies]
# PyTorch with CUDA from pytorch channel
# Version coupling: PyTorch 2.5.x requires torchvision 0.20.x, torchaudio 2.5.x
pytorch-cuda = { version = "12.4.*", channel = "pytorch" }
pytorch = { version = ">=2.5,<2.6", channel = "pytorch", build = "*cuda*" }
torchvision = { version = ">=0.20,<0.21", channel = "pytorch", build = "*cuda*" }
torchaudio = { version = ">=2.5,<2.6", channel = "pytorch", build = "*cuda*" }

# =============================================================================
# AIOS Agent OS Feature
# =============================================================================
# AIOS (AI Agent Operating System) requires strict dependency pinning
# to ensure compatibility with the agent kernel and Cerebrum SDK.
# See: https://github.com/agiresearch/AIOS
#      https://github.com/agiresearch/Cerebrum
# Activate with: pixi run -e aios <command>

[feature.aios]
# AIOS requires Python 3.10-3.11 (no 3.12+ support)
platforms = ["linux-64", "osx-64", "osx-arm64", "linux-aarch64"]

[feature.aios.dependencies]
# Core AIOS dependencies with strict pins for compatibility
pydantic = "==2.7.0"
numpy = "==1.24.3"

# LLM & Embedding dependencies
litellm = ">=1.0"
transformers = ">=4.30"
accelerate = ">=0.20"
sentence-transformers = ">=2.0"

# Vector database (AIOS default)
chromadb = ">=0.4"

# Cache & messaging
redis-py = ">=4.5.1"

# API server
fastapi = ">=0.100"
uvicorn = ">=0.20"

# Utilities
python-dotenv = ">=1.0"
watchdog = ">=2.1.9"
rich = ">=13.0"
click = "==8.1.7"

# NLP
nltk = ">=3.8"

# Cerebrum SDK dependencies
requests = ">=2.28"
platformdirs = ">=3.0"
datasets = ">=2.14"

# =============================================================================
# AIOS + CUDA Feature
# =============================================================================
# AIOS with GPU acceleration via vLLM
# Activate with: pixi run -e aios-cuda <command>

[feature.aios-cuda]
platforms = ["linux-64"]

[feature.aios-cuda.dependencies]
# Includes all AIOS dependencies plus vLLM
pydantic = "==2.7.0"
numpy = "==1.24.3"
litellm = ">=1.0"
transformers = ">=4.30"
accelerate = ">=0.20"
sentence-transformers = ">=2.0"
chromadb = ">=0.4"
redis-py = ">=4.5.1"
fastapi = ">=0.100"
uvicorn = ">=0.20"
python-dotenv = ">=1.0"
watchdog = ">=2.1.9"
rich = ">=13.0"
click = "==8.1.7"
nltk = ">=3.8"
requests = ">=2.28"
platformdirs = ">=3.0"
datasets = ">=2.14"

[environments]
default = { features = [], solve-group = "default" }
cuda = { features = ["cuda"], solve-group = "cuda" }
aios = { features = ["aios"], solve-group = "aios" }
aios-cuda = { features = ["aios", "aios-cuda", "cuda"], solve-group = "aios-cuda" }
