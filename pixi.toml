[workspace]
name = "robostack"
description = "Development environment for RoboStack ROS packages"
channels = ["robostack-humble", "conda-forge"]
platforms = ["linux-64", "osx-64", "osx-arm64", "linux-aarch64"]

[dependencies]
python = ">=3.11,<3.12"

# Build tools
compilers = ">=1.11.0,<2"
cmake = ">=4.2.0,<5"
pkg-config = ">=0.29.2,<0.30"
make = ">=4.4.1,<5"
ninja = ">=1.13.2,<2"

# Compilation cache & fast linking
ccache = ">=4.10,<5"
sccache = ">=0.8,<1"

# Archive/Network tools (for tree-sitter)
tar = ">=1.34"
curl = ">=8.0"

# Node.js ecosystem (for LazyVim plugins like peek.nvim, live-preview.nvim)
nodejs = ">=22.0,<23"    # LTS "Jod" - active until Apr 2027
pnpm = ">=9.0"

# ROS specific tools
rosdep = ">=0.26.0,<0.27"
colcon-common-extensions = ">=0.3.0,<0.4"
ros-humble-desktop = ">=0.10.0,<0.11"
catkin_tools = ">=0.8.2,<0.10"

# Testing & Code Quality
pytest = ">=7.0,<9"
pytest-cov = ">=4.0,<6"
mypy = ">=1.0,<2"
black = ">=24.0,<25"
isort = ">=5.0,<6"

# Scientific/ML dependencies (explicit)
numpy = ">=1.24,<3"

# PyTorch ML stack (CPU by default, CUDA via feature)
# Using conda-forge for native performance and ROS2 compatibility
# See docs/CONFLICTS.md for Python 3.14 and CUDA analysis
pytorch = ">=2.5,<3"
torchvision = ">=0.20,<1"
torchaudio = ">=2.5,<3"

[feature.cuda]
# CUDA-enabled PyTorch (requires NVIDIA GPU)
# Activate with: pixi run -e cuda <command>
platforms = ["linux-64"]

[feature.cuda.dependencies]
pytorch-cuda = "12.4"
pytorch = { version = ">=2.5,<3", build = "*cuda*" }
torchvision = { version = ">=0.20,<1", build = "*cuda*" }
torchaudio = { version = ">=2.5,<3", build = "*cuda*" }

[environments]
default = { features = [], solve-group = "default" }
cuda = { features = ["cuda"], solve-group = "cuda" }
