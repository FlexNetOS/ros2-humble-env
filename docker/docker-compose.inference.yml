
services:
  localai:
    image: localai/localai:v2.24.2-aio-cpu
    container_name: localai
    ports:
      - "8080:8080"
    environment:
      - THREADS=4
      - CONTEXT_SIZE=2048
      - MODELS_PATH=/models
      - DEBUG=true
      # OpenAI-compatible API endpoint
      - OPENAI_API_BASE=http://localhost:8080/v1
    volumes:
      - ./data/localai/models:/models:cached
      - ./data/localai/images:/tmp/generated/images:cached
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - agentic-network

  # Optional: LocalAI with GPU support (uncomment if NVIDIA GPU available)
  # localai-gpu:
  #   image: localai/localai:latest-aio-gpu-nvidia-cuda-12
  #   container_name: localai-gpu
  #   ports:
  #     - "8081:8080"
  #   environment:
  #     - THREADS=4
  #     - CONTEXT_SIZE=4096
  #     - MODELS_PATH=/models
  #     - DEBUG=true
  #   volumes:
  #     - ./data/localai/models:/models:cached
  #     - ./data/localai/images:/tmp/generated/images:cached
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
  #   restart: unless-stopped
  #   networks:
  #     - agentic-network

networks:
  agentic-network:
    external: true
    name: agentic-network

# Usage:
# 1. Create models directory: mkdir -p data/localai/models data/localai/images
# 2. Download models: 
#    curl -L https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf \
#      -o data/localai/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
# 3. Start: docker-compose -f docker-compose.localai.yml up -d
# 4. Test: curl http://localhost:8080/v1/models
# 5. OpenAI-compatible API: 
#    curl http://localhost:8080/v1/chat/completions \
#      -H "Content-Type: application/json" \
#      -d '{"model": "mistral-7b-instruct-v0.2.Q4_K_M.gguf", "messages": [{"role": "user", "content": "Hello!"}]}'
